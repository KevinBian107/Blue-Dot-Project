{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Playground Notebook\n",
    "This notebook is designed as a easy einterface to call the functions that we have defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_loader import load_participants_info, load_event_descriptions, load_behavioral_data, preprocess_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Let's prepare some data first to fit our model. We are specifically using [\"Locus coeruleus activity strengthens prioritized memories under arousal\"](https://openneuro.org/datasets/ds002011/versions/1.0.0) dataset fror now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data\"\n",
    "participants_df = load_participants_info(DATASET_PATH)\n",
    "load_event_descriptions(DATASET_PATH)\n",
    "\n",
    "df_behavior = load_behavioral_data(DATASET_PATH, \"01\")\n",
    "for idx in range(2,11):\n",
    "    sample_participant = f\"0{idx}\"\n",
    "    df = load_behavioral_data(DATASET_PATH, sample_participant)\n",
    "    df_behavior = pd.concat([df, df_behavior], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess our data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_tensor, Y_tensor, scaler_X, scaler_Y, df_clean = preprocess_data(df_behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_tensor, Y_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_feed_forward_nn, train_vanilla_rnn, train_vanilla_lc_model, train_lstm_lc_model, train_neural_gadget_model\n",
    "from analysis.evaluation import evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Network\n",
    "\n",
    "To illustrate our idea, we want to train 2 models from math and computer science, which is our vanilla feed forward networks and an recurrent networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ff = train_feed_forward_nn(X_train, Y_train,epochs=2000)\n",
    "evaluate_model(model_ff, X_test, Y_test, df_clean, scaler_Y=scaler_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurent Neural Networks\n",
    "\n",
    "We will  do the same thing with an recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = train_vanilla_rnn(X_train, Y_train, epochs=2000)\n",
    "evaluate_model(model_rnn, X_test, Y_test, df_clean, scaler_Y=scaler_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla LCNECortex Model\n",
    "\n",
    "Now coming to our customized LCNECortex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lc_vanilla = train_vanilla_lc_model(X_train, Y_train, epochs=2000)\n",
    "evaluate_model(model_lc_vanilla, X_test, Y_test, df_clean, scaler_Y=scaler_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM LCNECortex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lc_lstm = train_lstm_lc_model(X_train, Y_train, epochs=2000, hidden_dim=64)\n",
    "evaluate_model(model_lc_lstm, X_test, Y_test, df_clean, scaler_Y=scaler_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Gadget Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gadget = train_neural_gadget_model(X_train, Y_train, epochs=2000, hidden_dim=64)\n",
    "evaluate_model(model_gadget, X_test, Y_test, df_clean, scaler_Y=scaler_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.analysis import pca_gadget, pca_lcne_lstm, pca_feed_forward, pca_lcne, firing_lcne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_feed_forward(model_ff, X_tensor, df_behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCNECortex Model\n",
    "\n",
    "We will see that, though  under fitted with the real data, there are some structureness to the data that we can play around with since we injected mechanistic insights into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prev_LC = torch.zeros(X_tensor.shape[0], model_lc_vanilla.hidden_dim)\n",
    "    prev_Cortex = torch.zeros(X_tensor.shape[0], model_lc_vanilla.hidden_dim)\n",
    "\n",
    "    LC_act, NE_act, C_act, Pupil_pred, LC_raw, NE_raw, C_raw = model_lc_vanilla(X_tensor, prev_LC, prev_Cortex, return_activations=True)\n",
    "\n",
    "act_lc = LC_act.cpu().numpy()\n",
    "act_ne = NE_act.cpu().numpy()\n",
    "act_cortex = C_act.cpu().numpy()\n",
    "\n",
    "df_activations = pd.DataFrame({\n",
    "    'LC_Mean': act_lc.mean(axis=1),\n",
    "    'NE_Mean': act_ne.mean(axis=1),\n",
    "    'Cortex_Mean': act_cortex.mean(axis=1),\n",
    "    'PupilPred': Pupil_pred.cpu().numpy().squeeze(),\n",
    "    'ActualPupil': df_clean['Event_PupilDilation'].values  # Ensure this aligns with X_tensor\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df_activations['LC_Mean'], kde=True, bins=50, color='blue')\n",
    "plt.title(\"LC Activation Distribution\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df_activations['NE_Mean'], kde=True, bins=50, color='green')\n",
    "plt.title(\"NE Activation Distribution\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df_activations['Cortex_Mean'], kde=True, bins=50, color='red')\n",
    "plt.title(\"Cortex Activation Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_lcne(model_lc_vanilla, X_test, df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lcne(model_lc_vanilla, X_tensor, df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM LCNECortex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lcne_lstm(model_lc_lstm, X_tensor, df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Gadget Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_gadget(model_gadget, X_tensor, df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse251b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
